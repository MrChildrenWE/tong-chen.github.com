---
title: Records for bayes learning
author: Chen Tong
layout: post
description: 贝叶斯学习记录
modified:
categories:
  - math
tags:
  - bayes
---

这篇文章用于记录学习贝叶斯定理及其应用过程中的记录，希望由浅及深的提供
一份自我学习教程。

### 引子

* 概率的定义：概率是一个0-1之间的数，代表了我们对某个事实或预测的相信程度。

* 条件概率: 指基于某种背景信息的概率值。

* 联合概率：指2个或多个事件同时发生的概率。

* 事件独立性：一个事件的发生不影响其他事件即为事件的独行性。

* 概率的数学表示：事件A发生的概率写作 P(A), 事件B发生的概率写作 P(B), 
  给定事件A后事件B发生的概率 P(B|A), 事件A和B同时发生的概率P(A and B)。

* 事件的独立性用数学公式表示为：P(B|A) = P(B), P(A|B) = P(A) 
  A事件是否发生对B事件的发生没有影响，反之亦然，
  即表明A事件与B事件独立。

* 联合概率：P(A and B) = P(A) * P(B) 当事件A和B独立时，即
  P(B|A) = P(B), P(A|B) = P(A) 时。

  若事件A和事件B不一定相互独立呢？更通用的法则是：
    * P(A and B) = P(A) * P(B|A)
	* P(A and B) = P(B) * P(A|B)

* 我们举个例子：假设有袋圆球，罐1中有30个黑球和10个白球，
  罐2中黑球和白球各20个。某人随机的从一个罐子中取出一粒球，
  发现是黑球，问这个黑球从罐1中取出的概率有多大？

  这个问题怎么解答呢？

  问题是：黑球从罐1中取出的概率多大；这句话包含了2个事件，`黑球`和`罐1`.

  假如我们知道取得黑球的概率P(黑球)和给定黑球后球是从罐1取得的概率
  P(罐1|黑球)(这个是我们要计算的，假设个变量标记下就好), 
  我们可以计算出联合概率：
  P(黑球 and 罐1) = P(黑球)*P(罐1|黑球)

  另外我们也可以先选择罐1，然后再取出黑球，这样联合概率就是：	
  P(黑球 and 罐1) = P(罐1)*P(黑球|罐1)

  综合以上2个公式，我们就可以得到：
  P(黑球)*P(罐1|黑球) = P(罐1)*P(黑球|罐1)

  然后P(罐1|黑球) = P(罐1)*P(黑球|罐1) / P(黑球)
	              
  = P(罐1)*P(黑球|罐1) / (P(罐1)*P(黑球|罐1)+P(罐2)*P(黑球|罐2))

  = 0.5 * 0.75 / (0.5 * 0.75 + 0.5 * 0.5)

  = 0.6	

  注：这是一个简单的例子作为引子，是一个非常规解法。
  例子中的P(黑球)可以比较容易计算，所
  以我们只需要一步就可以算出黑球从罐1中取出的概率有多大。

### 贝叶斯定理

* 基于联合概率和条件概率的贝叶斯定理推导

  对于任意两个事件A和B，P(A and B) = P(B and A);

  P(A and B) = P(A) * P(B|A)

  P(B and A) = P(B) * P(A|B)

  P(A|B) = P(A)*P(B|A)/P(B)

  P(B|A) = P(B)*P(A|B)/P(A)

  在有了这两个转换之后，我们就可以用已知的或者容易观察的数据来计算未知
  的，不容易观察到的部分。

* 贝叶斯定理解释

  



![MSA and adaptor clipping]({{ site.img_url }}/smRNA-seq-1.jpg)

### References

* [Think bayes](https://github.com/AllenDowney/ThinkBayes)
* [数学之美番外篇：平凡而又神奇的贝叶斯方法](http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/)

